version: "3.7"

x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"

services:
  # HTTP Proxy for identifying sessions
  # https://github.com/mu-semtech/mu-identifier
  identifier:
    image: semtech/mu-identifier:1.10.3
    environment:
      SESSION_COOKIE_SECURE: "on"
      DEFAULT_MU_AUTH_ALLOWED_GROUPS_HEADER: '[{"variables":[],"name":"public"}]'
      DEFAULT_ACCESS_CONTROL_ALLOW_ORIGIN_HEADER: "*"
    links:
      - dispatcher:dispatcher
    restart: always
    logging: *default-logging
    labels:
      - "logging=true"

  # Reverse proxy that configures endpoints
  # https://github.com/mu-semtech/mu-dispatcher
  dispatcher:
    image: semtech/mu-dispatcher:2.0.0
    links:
      - resources:resource
    volumes:
      - ./config/dispatcher:/config
    restart: always
    logging: *default-logging
    labels:
      - "logging=true"

  # Front-end made for BNB
  # https://github.com/lblod/frontend-burgernabije-besluitendatabank
  frontend:
    image: lblod/frontend-burgernabije-besluitendatabank:0.8.0
    links:
      - identifier
    restart: always
    logging: *default-logging
    labels:
      - "logging=true"

  # Proxy for mu-cl-resources that allows caching
  # https://github.com/mu-semtech/mu-cache
  cache:
    image: semtech/mu-cache:2.0.2
    links:
      - resources:backend
    restart: always
    logging: *default-logging
    labels:
      - "logging=true"

  # Allows accessing linked data as a JSON:API endpoint. Used by frontend
  # https://github.com/mu-semtech/mu-cl-resources
  resources:
    image: semtech/mu-cl-resources:1.25.0
    environment:
      CACHE_CLEAR_PATH: "http://cache/.mu/clear-keys"
    links:
      - database:database
    volumes:
      - ./config/resources:/config
    restart: always
    logging: *default-logging
    labels:
      - "logging=true"

  # Allows running .sparql & .ttl files to the triplestore
  # https://github.com/mu-semtech/mu-migrations-service
  migrations:
    image: semtech/mu-migrations-service:0.9.0
    links:
      - triplestore:database
    environment:
      MU_SPARQL_TIMEOUT: "300"
    volumes:
      - ./config/migrations:/data/migrations
    restart: always
    logging: *default-logging
    labels:
      - "logging=true"

  # SPARQL Endpoint authorization service. Adds an authentication layer to the triplestore
  # https://github.com/mu-semtech/sparql-parser
  database:
    image: semtech/sparql-parser:0.0.13
    volumes:
      - ./config/authorization:/config
      - ./data/authorization:/data
    restart: always
    logging: *default-logging
    labels:
      - "logging=true"

  # A linked-data database. All consumed data ends up here
  # https://github.com/redpencilio/docker-virtuoso
  triplestore:
    image: redpencil/virtuoso:1.2.0
    environment:
      SPARQL_UPDATE: "true"
      DEFAULT_GRAPH: "http://mu.semte.ch/graphs/public"
    volumes:
      - ./data/db:/data
      - ./config/virtuoso/virtuoso.ini:/data/virtuoso.ini
    restart: always
    logging: *default-logging
    labels:
      - "logging=true"

  # Sends notifications to the uuid-generation & resources when new data is found on specific data.vlaanderen.be urls
  # https://github.com/mu-semtech/delta-notifier
  delta-notifier:
    image: semtech/mu-delta-notifier:0.4.0
    volumes:
      - ./config/delta:/config
    restart: always
    logging: *default-logging
    labels:
      - "logging=true"

  # Service that generates uuid's for imported data to allow linked-data usage
  # https://github.com/redpencilio/uuid-generation-service
  uuid-generation:
    image: redpencil/uuid-generation:0.3.0
    volumes:
      - ./config/uuid-generation/:/config
    links:
      - triplestore:database
    restart: always
    logging: *default-logging
    labels:
      - "logging=true"

  # Imports endpoint data into the triplestore
  # https://github.com/lblod/delta-consumer
  mandatendatabank-consumer:
    image: lblod/delta-consumer:0.0.26
    environment:
      DCR_SYNC_BASE_URL: "https://loket.lokaalbestuur.vlaanderen.be/"
      DCR_SERVICE_NAME: "mandatendatabank-consumer"
      DCR_SYNC_FILES_PATH: "/sync/mandatarissen/files"
      DCR_SYNC_DATASET_SUBJECT: "http://data.lblod.info/datasets/delta-producer/dumps/MandatarissenCacheGraphDump"
      DCR_INITIAL_SYNC_JOB_OPERATION: "http://redpencil.data.gift/id/jobs/concept/JobOperation/deltas/consumer/initialSync/mandatarissen"
      DCR_DELTA_SYNC_JOB_OPERATION: "http://redpencil.data.gift/id/jobs/concept/JobOperation/deltas/consumer/mandatarissenSyncing"
      DCR_JOB_CREATOR_URI: "http://data.lblod.info/services/id/mandatendatabank-consumer"
      DCR_KEEP_DELTA_FILES: "false"
      DCR_DELTA_FILE_FOLDER: "/consumer-files"
      DCR_DISABLE_DELTA_INGEST: "true" # toggle this in override, leave 'true' in default docker-compose.yml
      DCR_DISABLE_INITIAL_SYNC: "true" # toggle this in override, leave 'true' in default docker-compose.yml
      BYPASS_MU_AUTH_FOR_EXPENSIVE_QUERIES: "false"
      DIRECT_DATABASE_ENDPOINT: "http://triplestore:8890/sparql"
      BATCH_SIZE: 250
    volumes:
      - ./data/files/consumer-files/mandaten:/consumer-files/
    restart: always
    logging: *default-logging
    labels:
      - "logging=true"
  op-public-consumer:
    image: lblod/delta-consumer:0.0.26
    environment:
      DCR_SYNC_BASE_URL: "https://organisaties.abb.vlaanderen.be/"
      DCR_SERVICE_NAME: "op-public-consumer"
      DCR_SYNC_FILES_PATH: "/sync/public/files"
      DCR_SYNC_DATASET_SUBJECT: "http://data.lblod.info/datasets/delta-producer/dumps/PublicCacheGraphDump"
      DCR_INITIAL_SYNC_JOB_OPERATION: "http://redpencil.data.gift/id/jobs/concept/JobOperation/deltas/consumer/initialSync/op-public"
      DCR_DELTA_SYNC_JOB_OPERATION: "http://redpencil.data.gift/id/jobs/concept/JobOperation/deltas/consumer/deltaSync/op-public"
      DCR_JOB_CREATOR_URI: "http://data.lblod.info/services/id/op-public-consumer"
      DCR_KEEP_DELTA_FILES: "false"
      DCR_DELTA_FILE_FOLDER: "/consumer-files"
      DCR_DISABLE_DELTA_INGEST: "true" # toggle this in override, leave 'true' in default docker-compose.yml
      DCR_DISABLE_INITIAL_SYNC: "true" # toggle this in override, leave 'true' in default docker-compose.yml
      BYPASS_MU_AUTH_FOR_EXPENSIVE_QUERIES: "false"
      DIRECT_DATABASE_ENDPOINT: "http://triplestore:8890/sparql"
      BATCH_SIZE: 250
    volumes:
      - ./data/files/consumer-files/op-public:/consumer-files/
    restart: always
    logging: *default-logging
    labels:
      - "logging=true"

  swarm-consumer:
    image: nbittich/sync-consumer:0.1.4
    environment:
      SWARM_BASE_URL: http://job-manager
      SWARM_USERNAME: bnb
      RUST_LOG: debug
      SWARM_PASSWORD: bnb
      ENABLE_INITIAL_SYNC: "true"
      # START_FROM_DELTA_TIMESTAMP: "2025-01-01T20:40:21.384141291Z"
      DELTA_ENDPOINT: http://search/update
      ENABLE_DELTA_PUSH: "true"
      CHUNK_SIZE: 100
      TARGET_GRAPH: http://mu.semte.ch/graphs/public
      ROOT_OUTPUT_DIR: /consumer-files
      SPARQL_ENDPOINT: http://triplestore:8890/sparql
    volumes:
      - ./data/files/consumer-files/besluiten:/consumer-files/
    restart: always
    logging: *default-logging
    labels:
      - "logging=true"
  # Search facility for mu-semtech, powered by ElasticSearch
  # https://github.com/mu-semtech/mu-search
  search:
    image: semtech/mu-search:0.10.0
    volumes:
      - ./config/search:/config
    restart: always
    logging: *default-logging
    labels:
      - "logging=true"
  # Elasticsearch backend to be used with mu-search
  # https://github.com/mu-semtech/mu-search-elastic-backend/
  elasticsearch:
    image: semtech/mu-search-elastic-backend:1.1.0
    volumes:
      - ./data/elasticsearch/:/usr/share/elasticsearch/data
    environment:
      - discovery.type=single-node
    restart: always
    logging: *default-logging
    labels:
      - "logging=true"
  # Generic service to generate reports about data
  # https://github.com/lblod/loket-report-generation-service
  report-generation:
    image: lblod/loket-report-generation-service:0.8.2
    environment:
      LOG_SPARQL_ALL: "false"
      DEBUG_AUTH_HEADERS: "false"
    links:
      - database:database
    volumes:
      - ./data/files:/share
      - ./config/reports:/config
    labels:
      - "logging=true"
    restart: always
    logging: *default-logging
  # Provides endpoints to download the most recent version of data exports
  # https://github.com/lblod/download-exports-service
  download-exports:
    image: lblod/download-exports-service:0.1.0
    links:
      - database:database
    volumes:
      - ./data/files:/share
    labels:
      - "logging=true"
    restart: always
    logging: *default-logging
